<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Han</title><meta name="author" content="Yinhan Zhang"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Han</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="https://yinhan-zhang.github.io/"> About</a></li><li class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://blog.csdn.net/randyhan/category_12318474.html"> Blog</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>Yinhan Zhang</h3><p class="author-bio">Data Science</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-facebook-square" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://github.com/YinHan-Zhang" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-stack-overflow" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weibo" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weixin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="1513032551" target="_blank"><i class="fab fa-qq" aria-hidden="true"></i></a></li><li><a class="social-icon" href="1513032551@qq.com" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fas fa-rss" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="/" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="/" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div><a class="cv-links" href="/attaches/CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>My Detail CV.</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">index</h2><article><h2 id="Personal-Statement"><a href="#Personal-Statement" class="headerlink" title="Personal Statement:"></a>Personal Statement:</h2><blockquote>
<p>I am a person with active thinking, who enjoys communication and has strong coding skills. During my 3 years of undergraduate study, my research focus in the laboratory was medical data mining, image analysis and robotics. I am passionate about machine learning algorithms and have a strong interest in scientific research. I am skilled in reading academic papers and am a formal member of the AI open source learning organization, DataWhale. I have participated in the development of AI teaching and exercise projects, and have a habit of writing blogs.</p>
<p>During my undergraduate studies, I participated in collaborative projects between the laboratory and several hospitals, including segmentation and quantitative analysis of the prostate and liver using structured data from hospital-provided imaging studies, establishment of postoperative risk prediction models for patient risk assessment, and participation in tumor area calculations. Successful outputs include body composition analysis of liver cirrhosis [1], 3D image segmentation models [2], and machine learning of phase-separated order parameters using graph networks (a cross-disciplinary field between machine learning and physics) [3], which are currently under review. In July of last year, I participated in Tencent’s talent development program and learned Hadoop, Spark, and graph representation learning algorithms under the guidance of an industry mentor. In May of this year, I began working as a research intern under the guidance of Dr. Li Ziqing’s Ph.D. students to study deep learning protein structure prediction (RefineGNN, Diffab, and MEAN). In addition, I have studied time series analysis modeling and Raspberry Pi robot-related knowledge in extracurricular technology competitions and achieved good results. I am very interested in deep learning-based protein molecular prediction and am currently conducting experiments using server code for related models.</p>
</blockquote>
<h1 id="Publications"><a href="#Publications" class="headerlink" title="Publications:"></a>Publications:</h1><h2 id="《Survival-analysis-of-patients-with-liver-cirrhosis-based-on-deep-learning-to-quantify-body-composition》"><a href="#《Survival-analysis-of-patients-with-liver-cirrhosis-based-on-deep-learning-to-quantify-body-composition》" class="headerlink" title="《Survival analysis of patients with liver cirrhosis based on deep learning to quantify body composition》"></a><strong>《Survival analysis of patients with liver cirrhosis based on deep learning to quantify body composition》</strong></h2><ul>
<li>Liver International (under review)</li>
</ul>
<p><strong>Abstract:</strong></p>
<blockquote>
<p>Early body composition analysis in patients with liver cirrhosis is important for correcting malnutrition and improving prognosis and quality of life. Severe muscle wasting or Sarcopenia is the most common and often undetected complication, with serious negative effects on survival and quality of life. The purpose of this study was to use deep learning methods to segment and quantify body composition, and to determine Skeletal muscle reduced Visceral Obesity ( SVO ) by Skeletal Muscle Index ( SMI ) and Visceral to Subcutaneous adipose tissue Ratio ( VSR ) to examine its relationship with survival in patients with cirrhosis. In this paper, a new segmentation framework MCAUnet based on deep learning is proposed. The framework adds an attention mechanism from the perspective of the channel, which can adaptively fuse enough channel features to facilitate complex medical image segmentation. Compared with the previous segmentation model, the effect is optimal ( Dice &#x3D; 0.952 ). We analyzed 117 adult patients with cirrhosis who were admitted to Shanxi Bethune Hospital between January 2016 and December 2020. SOV was defined as Sarcopenia ( male SMI &lt;43.24 cm2 &#x2F; m2, female SMI &lt; 35.11 cm2 &#x2F; m2 ) and visceral obesity ( male VSR ≥ 1.07, female VSR ≥0.68 ). 18.8 % of the subjects met the SOV criteria. Through survival analysis, the 3-year and 5-year survival rates of SVO patients were significantly lower than those of normal patients ( 32 % VS50 %, 5 % VS32 % ) [ P &#x3D; 0.035 ]. In regression analysis, SVO was associated with mortality in patients with cirrhosis ( hazard ratio 0.54,95 % confidence interval 0.3-0.97 ), and still significant after multiple regression analysis ( hazard ratio 0.62,95 % confidence interval 0.31-1.3 ). Overall, SVO is associated with reduced survival in patients with cirrhosis, and further prospective studies and studies in other populations are needed to evaluate the model and the actual predictive effect of SVO.</p>
</blockquote>
<p><strong>K</strong> <strong>E</strong> <strong>Y</strong> <strong>W</strong> <strong>O</strong> <strong>R</strong> <strong>D</strong> <strong>S</strong></p>
<p>Cirrhosis, Body Composition, Skeletal muscle reduced Visceral Obesity</p>
<p><strong>CONCLUSION</strong></p>
<blockquote>
<p>In summary, this study shows that the presence of L3 layer SVO determined by CT images of patients with cirrhosis can be used to predict OS in patients with cirrhosis. Furthermore, compared with other criteria used in previous studies ( MELD score and total body fat content ), the use of SVO to distinguish patients has higher reliability in predicting the overall survival of patients with cirrhosis. Surgeons should therefore pay more attention to the presence of patients with sarcopenic visceral obesity, which can help to personalize nutritional therapy promptly, reduce postoperative complications and improve the long-term prognosis of patients.</p>
</blockquote>
<p><strong>Github Code Link:</strong>  <a target="_blank" rel="noopener" href="https://github.com/YinHan-Zhang/MCAUnet">https://github.com/YinHan-Zhang/MCAUnet</a></p>
<p><a href="https://yinhan-zhang.github.io/attaches/SAM.pdf">paper link</a></p>
<hr>
<hr>
<h2 id="《Efficient-multi-scale-spatial-aware-3D-abdominal-multi-organ-segmentation-mode》"><a href="#《Efficient-multi-scale-spatial-aware-3D-abdominal-multi-organ-segmentation-mode》" class="headerlink" title="《Efficient multi-scale spatial aware 3D abdominal multi-organ segmentation mode》"></a><strong>《Efficient multi-scale spatial aware 3D abdominal multi-organ segmentation mode》</strong></h2><ul>
<li>(under review)</li>
</ul>
<p><strong>Abstract</strong> </p>
<blockquote>
<p>Abdominal CT scans are naturally 3D images, and past models that only segmented 2D slices did not make good use of image contextual information, while processing 3D image data was computationally costly. In order to make full use of the context information of 3D images and reduce the computational cost it brings, we develop an efficient multi-scale spatial aware model for 3D abdominal multi-organ segmentation. Our proposed model consists mainly of an encoder, decoder, lightweight spatial attention and hybrid pooling modules. We use 1D kernels and 2D kernels in the encoder and decoder modules to simulate a large 3D kernel for reducing the number of parameters and computational cost, while to better capture and exploit spatially contextual information ,we use lightweight spatial attention and hybrid pooling modules to capture cross-dimensional information, multi-scale features and long-range contextual information. We achieved a DSC of 89.86 and an NSD of 78.2 on the FLARE data set. At the same time, the GPU occupation is only 1183MB, the parameter size is 9MB and the FLOPS is 335GB.Our model can achieve segmentation performance comparable to the best models with less number of parameters, lower memory usage and lower computational power.</p>
</blockquote>
<p><strong>Key words</strong>  3D segmentation;  Efficient segmentation model;  Light weight segmentation model;  Multi-scale;  abdominal multi-organ segmentation;</p>
<p><strong>Conclusion</strong></p>
<blockquote>
<p>the purpose of this study was to explore a lightweight and highly generalizable 3D multi-organ segmentation model that can maintain high performance. The proposed model aimed to address the limitations of existing models, including high computational costs and poor generalization ability. The proposed model framework incorporated multiple optimization strategies, such as a hybrid pooling module that can capture multi-scale and long-range information and a lightweight attention model that can capture spatial information across dimensions. To reduce model complexity, we used convolutional decomposition, convolution, and pooling instead of attention to obtain long-range and spatial information. The proposed method demonstrated excellent performance in healthy or mildly affected organs and exhibited strong stability when dealing with multi-phase and multi-center FLARE datasets. The DSC and NSD metrics showed that our method achieved high segmentation accuracy for the liver, kidney, and spleen, while significantly reducing the model complexity and training prediction time compared to models with similar DSC and NSD performance. Our model achieved high performance while using fewer resources, making it suitable for practical applications.However, 3D imaging contains more information than 2D imaging, which increases the model’s parameter count and computational resource burden, potentially leading to practical application difficulties. Although our model can effectively address this issue, 3D fully supervised models rely heavily on high-quality annotated data for training and typically require a large number of 3D image annotations. Inaccurate or incomplete annotation data can also affect model performance, and 3D image annotation is a hundred times more expensive than 2D image annotation. In the future, we plan to use semi-supervised or self-supervised methods that can significantly reduce dataset requirements while incorporating pre-training methods to accelerate model convergence speed, making it more suitable and convenient for training on new datasets.</p>
</blockquote>
<p><a href="https://yinhan-zhang.github.io/attaches/3D.pdf">paper link</a></p>
<hr>
<h2 id="Machine-learning-for-phase-separation-order-parameters-by-using-graph-networks"><a href="#Machine-learning-for-phase-separation-order-parameters-by-using-graph-networks" class="headerlink" title="Machine learning for phase separation order parameters by using graph networks"></a><strong>Machine learning for phase separation order parameters</strong> <strong>by using graph networks</strong></h2><p><strong>Abstract</strong></p>
<blockquote>
<p>Phase separation, the process of spontaneous separation of components of multi-component mixtures, is a key aspect of many physical, chemical and biological systems. In this work, we used dissipative particle dynamics to implement the process of phase separation. We designed an order parameter based on local density to measure the evolution of phase separation, and simulated the phase separation process under different repulsion coefficient and different Schmidt numbers. We show that the order parameter can accurately describe the phase separation in different states. Meanwhile, we propose a graph network-based data-driven approach to accurately predict the evolution of the ordinal covariance and the long-term evolution of the particle positions of the phase separation system from the position and species of the particles at the initial moment only, combined with the conserved forces and relative distances of the particle interactions as features to learn the changes of the droplet aggregation during the simulation. </p>
</blockquote>
<p><strong>Conclusions</strong> </p>
<blockquote>
<p>In this work, we simulated the phase separation of binary mixtures under different conditions and measured the evolution of the phase separation by introducing an ordinal parameter of local density. The results show that our order parameter can effectively describe the process of two-phase separation and is validated for different systems. Besides, we design a data-driven GNN model based on the particle characteristics of the initial position only, and by learning the conserved forces and relative distances between the characteristic particle pairs, we successfully predict the sequence covariance changes inmultiple states and make longterm predictions for the particle positions. Experiments demonstrate that our model has strong robustness and can be suitable for phase separation models in a variety of regimes. The machine learning principle of our proposed model can be used for new multipurpose applications, as it can acquire the ability to predict long-term particle positions due to kinetic properties, which is of special interest for physical simulations. As a next step, we intend to introduce the GNN model within the 3D phase separation system, considering the phase order competition between multiple constituents and the phase separation process due to specific substances (colloids, block copolymers, etc.). Also adding specific structural and angular descriptors is something we have been wanting to do, which will facilitate the integration of data science and physical simulation even more.</p>
</blockquote>
<p><a href="https://yinhan-zhang.github.io/attaches/ML.pdf">paper link </a></p>
<hr>
<h1 id="Project"><a href="#Project" class="headerlink" title="Project"></a>Project</h1><h2 id="Surgical-Data-Ming"><a href="#Surgical-Data-Ming" class="headerlink" title="Surgical Data Ming"></a>Surgical Data Ming</h2><p>Backgroud</p>
<blockquote>
<p>Currently, there are over one million organ transplant recipients worldwide, with nearly 300,000 of them having received kidney transplants. In China, the number of kidney transplant recipients is close to 30,000. Kidney transplant involves transplanting a healthy kidney from a donor to a patient who has kidney disease and has lost kidney function. The human body has two kidneys, and when both kidneys lose function (bilateral kidney failure), kidney transplant is the most ideal treatment method.</p>
<p><strong>eGFR</strong> (estimated glomerular filtration rate) is an internationally recognized indicator that can effectively reflect the filtering function of the kidneys. A higher eGFR value indicates better kidney function. It is an important criterion for determining whether postoperative patients have abnormal kidney function.</p>
</blockquote>
<p><strong>Current Research Pain Point 1:</strong></p>
<p>In terms of statistics, the use of generalized linear models to study variables is limited by covariance and collinearity, which can be explained but the results are not satisfactory.</p>
<p><strong>Current Research Pain Point 2:</strong></p>
<p>In terms of machine learning, the analysis of features is simple and relies on models, without in-depth exploration of data.</p>
<p><strong>Proposed Ideas:</strong></p>
<ol>
<li>Use machine learning models to break free from linear constraints and study features.</li>
<li>Return to linear models for statistical interpretation.</li>
<li>Study data without relying on models.</li>
</ol>
<p><strong>My Reselt:</strong></p>
<ol>
<li>Obtained important factors that affect kidney transplant outcomes, constructed and selected 10 indicators. Two were existing original data (but overlooked by doctors) and eight were constructed as temporal features. <strong>The model is simple, and all features passed statistical tests, making the model highly interpretable.</strong></li>
<li><strong>Quantified the indicators.</strong> Defined a formula to calculate the risk index and defined the risk index S to quantify the risk of postoperative recurrence.</li>
<li><strong>Interpreted the clinical significance of the risk index.</strong> Studied the real-world significance of the gradient based on the defined formula and evaluated and optimized the calculation of the existing GFR formula.</li>
<li><strong>Validated the conclusion.</strong> Calculated the risk index for all patients in the existing dataset of 345 and compared it with their original classification labels, demonstrating the role and significance of the risk index.</li>
</ol>
<p> <img src="/2023/05/14/index/1.png" alt="1684282988455"></p>
<p><img src="/2023/05/14/index/2.png" alt="1684283049692"></p>
<p><strong>Meaning:</strong></p>
<ul>
<li>By calculating the risk coefficient S, the GFR value can be optimized to reduce misjudgment, and the calculated risk coefficient S can be used to determine the risk trend.</li>
</ul>
<h1 id="Github-Project"><a href="#Github-Project" class="headerlink" title="Github Project"></a>Github Project</h1><p>• I created this project to make the boring and difficult-to-understand algorithms of AI interesting, and to  </p>
<p>teach learners how to apply AI to real-life situations. </p>
<p>• I am trying to combine GPT with robotics to do some fun things. </p>
<p>Here is the Website link: <a target="_blank" rel="noopener" href="http://ai.9998k.cn/">http://ai.9998k.cn</a></p>
<p>github link :<a target="_blank" rel="noopener" href="https://github.com/YinHan-Zhang/Mutual-AI">https://github.com/YinHan-Zhang/Mutual-AI</a></p>
<hr>
<h1 id="Robot"><a href="#Robot" class="headerlink" title="Robot"></a>Robot</h1><h2 id="InterShip"><a href="#InterShip" class="headerlink" title="InterShip"></a>InterShip</h2><p><strong>I am interested in robotics and have an active mind and enjoy hands-on practice.</strong></p>
<ol>
<li>I will be interning at Zhiyuan Education Co., Ltd. in Shenzhen during the summer of 2022. During my internship, I will be using Raspberry Pi to create some small teaching demos, such as a simple facial recognition access control device and a mechanical arm sorting system for simulating a factory production line.</li>
<li>I am participating in artificial intelligence and robotics competitions, including the RobotCup competition, where the task is to automatically pick fruits and crops and intelligently identify and irrigate them. We have already passed the provincial competition.</li>
</ol>
<p><img src="/2023/05/14/index/3.jpg" alt="IMG_20220805_172130"></p>
<h1 id="Contest"><a href="#Contest" class="headerlink" title="Contest"></a>Contest</h1><p><strong>&lt; The National College Student Internet+ Innovation and Entrepreneurship Competition &gt;</strong></p>
<ul>
<li>National Second Prize</li>
</ul>
<p><strong>&lt; The China Software Cup National College Student Software Design Competition &gt;</strong></p>
<ul>
<li>National Second Prize</li>
</ul>
<p><strong>&lt; The 2022 BDCI Competition’s Criminal sentence reduction prediction &gt;</strong></p>
<ul>
<li>10th Place (10&#x2F;482)</li>
</ul>
<p><strong>&lt; The Chinese Robotics and Artificial Intelligence Competition &gt;</strong></p>
<ul>
<li>National Third Prize.</li>
</ul>
<p><strong>&lt;  The National College Student Mathematical Modeling Competition &gt;</strong></p>
<ul>
<li>The second prize in the Shanxi Province</li>
</ul>
<p><img src="/2023/05/14/index/4.jpg" alt="微信图片_20230503223915"></p>
<h1 id="Supercomputer"><a href="#Supercomputer" class="headerlink" title="Supercomputer"></a>Supercomputer</h1><ol>
<li>I am the person in charge of the Supercomputing Base at Taiyuan University of Technology.</li>
<li>I have a lot of experience in conducting experiments using servers to train deep learning models.</li>
<li>The main models that I have used include Unet for image segmentation, GNNs for graph neural networks, and Diffusion models.</li>
</ol>
<hr>
<h1 id="Volunteer-Work-With-AI"><a href="#Volunteer-Work-With-AI" class="headerlink" title="Volunteer Work With AI"></a>Volunteer Work With AI</h1><p><strong>Hands-on Learning of Deep Learning, DataWhale  Course Assistant</strong> </p>
<p>• The DataWhale team I belong to contacted Professor Li Mu and organized the “Hands-on Deep Learning”  </p>
<p>course, attracted 9,027 students from 733 universities around the world to join the group for learning. </p>
<p>• I was one of ths, helping and solving problems for students during the learning process. </p>
<p><img src="/2023/05/14/index/5.png" alt="mmexport1680772964370"></p>
<p><img src="/2023/05/14/index/6.png" alt="mmexport1684118436135"></p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="https://yinhan-zhang.github.io/"> About</a></li><li class="nav_item"><a class="nav-page" target="_blank" rel="noopener" href="https://blog.csdn.net/randyhan/category_12318474.html"> Blog</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2023 by Yinhan Zhang</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>